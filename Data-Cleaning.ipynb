{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract the jsonl file from jsonl.gz file\n",
    "\n",
    "def extract_jsonl(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        data = f.readlines()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now convert the jsonl file to a csv file\n",
    "\n",
    "def jsonl_to_csv(data, csv_file):\n",
    "    data = [json.loads(x) for x in data]\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1.csv created\n",
      "dataset2.csv created\n",
      "dataset3.csv created\n",
      "dataset4.csv created\n",
      "dataset5.csv created\n",
      "dataset6.csv created\n",
      "dataset7.csv created\n",
      "dataset8.csv created\n",
      "dataset9.csv created\n"
     ]
    }
   ],
   "source": [
    "# Now the files are named 'dataset1.jsonl.gz' to 'dataset9.jsonl.gz' and the csv files will be named 'dataset1.csv' to 'dataset9.csv'\n",
    "\n",
    "for i in range(1, 10):\n",
    "    data = extract_jsonl(f'dataset{i}.jsonl.gz')\n",
    "    jsonl_to_csv(data, f'dataset{i}.csv')\n",
    "    print(f'dataset{i}.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a general code for the files named 'file.csv' to be converted to 'file_clean.csv'\n",
    "\n",
    "def clean_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    df = df[df['description'] != '[]']\n",
    "    df.to_csv(file.replace('.csv', '_clean.csv'), index=False)\n",
    "    df = df[['main_category', 'title', 'features', 'description', 'images', 'details']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1_clean.csv created\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rujul\\AppData\\Local\\Temp\\ipykernel_14080\\166219179.py:4: DtypeWarning: Columns (14,15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset2_clean.csv created\n",
      "dataset3_clean.csv created\n",
      "dataset4_clean.csv created\n",
      "dataset5_clean.csv created\n",
      "dataset6_clean.csv created\n",
      "dataset7_clean.csv created\n",
      "dataset8_clean.csv created\n",
      "dataset9_clean.csv created\n"
     ]
    }
   ],
   "source": [
    "# Now clean the files\n",
    "\n",
    "for i in range(1, 10):\n",
    "    df = clean_csv(f'dataset{i}.csv')\n",
    "    print(f'dataset{i}_clean.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_dataset.csv created\n"
     ]
    }
   ],
   "source": [
    "# Now merge all the files into one csv file in a randomised order\n",
    "\n",
    "df = pd.concat([pd.read_csv(f'dataset{i}_clean.csv') for i in range(1, 10)])\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "df.to_csv('merged_dataset.csv', index=False)\n",
    "print('merged_dataset.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.csv created\n"
     ]
    }
   ],
   "source": [
    "# Only have the following columns: 'main_category', 'title', 'features', 'description', 'images', 'details'\n",
    "\n",
    "df = df[['main_category', 'title', 'features', 'description', 'images', 'details']]\n",
    "df.to_csv('dataset.csv', index=False)\n",
    "print('dataset.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main_category: 4677 missing values\n",
      "title: 23 missing values\n",
      "features: 0 missing values\n",
      "description: 0 missing values\n",
      "images: 0 missing values\n",
      "details: 0 missing values\n"
     ]
    }
   ],
   "source": [
    "# Now check how many null values or missing values are there in each column (one column at a time)\n",
    "\n",
    "for col in df.columns:\n",
    "    print(f'{col}: {df[col].isnull().sum()} missing values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_final.csv created\n"
     ]
    }
   ],
   "source": [
    "# As we can see, only main_category and title have missing values. We can remove the rows with missing values\n",
    "\n",
    "df = df.dropna()\n",
    "df.to_csv('dataset_final.csv', index=False)\n",
    "print('dataset_final.csv created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_final_cleaned.csv created\n"
     ]
    }
   ],
   "source": [
    "# Some rows in features column have '[]' as values. We can remove those rows as well\n",
    "\n",
    "df = df[df['features'] != '[]']\n",
    "df.to_csv('dataset_final_cleaned.csv', index=False)\n",
    "print('dataset_final_cleaned.csv created')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
